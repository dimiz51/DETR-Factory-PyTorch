{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing and training a Detection Transformer (DETR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import ops\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Import the custom COCO dataset loader\n",
    "from dataloaders.coco_od_pytorch import TorchCOCOLoader, collate_fn\n",
    "from models.detr import DETR\n",
    "from models.losses.detr_loss import compute_batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the experiment configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for dataloaders and image size for model/pre-processing\n",
    "BATCH_SIZE = 2\n",
    "IMAGE_SIZE = 480\n",
    "CUDA_ENABLED = True if torch.cuda.is_available() else False\n",
    "MAX_OBJECTS = 100\n",
    "FREEZE_BACKBONE = True\n",
    "EPOCHS = 1\n",
    "LOG_FREQUENCY = 1 # Training-time losses will be logged according to this frequency\n",
    "SAVE_FREQUENCY = 20 # Model weights will be saved according to this frequency\n",
    "device = torch.device(\"cuda\" if CUDA_ENABLED else \"cpu\") # Training device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a PyTorch Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class labels for \"vehicles_dataset\"\n",
    "CLASSES = [\"N/A\", \"vehicle\"]\n",
    "EMPTY_CLASS_ID = 0 # ID of the dataset classes to treat as \"empty\" class\n",
    "\n",
    "# NOTE: You can instead load the COCO CLASSES if you wish to train on the COCO dataset\n",
    "#       by importing \"from datasets_info.available_classes import DATASET_CLASSES\". This\n",
    "#       is a lookup dictionary in the format:\n",
    "#       DATASET_CLASSES = {\n",
    "#           \"coco\" : {\n",
    "#               \"class_names\" : COCO_CLASSES,\n",
    "#               \"empty_class_id\": 91\n",
    "#           }\n",
    "#           ....\n",
    "#       }\n",
    "\n",
    "\n",
    "# Load and COCO dataset (adjust the paths accordingly)\n",
    "coco_ds_train = TorchCOCOLoader(\n",
    "    '../data/vehicles_dataset/train',\n",
    "    '../data/vehicles_dataset/train/_vehicle_annotations.json',\n",
    "    max_boxes=MAX_OBJECTS,\n",
    "    empty_class_id=EMPTY_CLASS_ID,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")\n",
    "\n",
    "coco_ds_val = TorchCOCOLoader(\n",
    "    '../data/vehicles_dataset/valid',\n",
    "    '../data/vehicles_dataset/valid/_vehicle_annotations.json',\n",
    "    max_boxes=MAX_OBJECTS,\n",
    "    empty_class_id=EMPTY_CLASS_ID,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    coco_ds_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    coco_ds_val, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Training dataset size: {len(coco_ds_train)}\")\n",
    "print(f\"Validation dataset size: {len(coco_ds_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils.visualizers import DETRBoxVisualizer\n",
    "\n",
    "# Create a visualizer\n",
    "visualizer = DETRBoxVisualizer(class_labels= CLASSES,\n",
    "                               empty_class_id=0)\n",
    "\n",
    "# Visualize batches\n",
    "dataloader_iter = iter(train_loader)\n",
    "for i in range(1):\n",
    "    input_, (classes, boxes, masks) = next(dataloader_iter)\n",
    "    fig = plt.figure(figsize=(10, 10), constrained_layout=True)\n",
    "\n",
    "    for ix in range(4):\n",
    "        t_cl = classes[ix]\n",
    "        t_bbox = boxes[ix]\n",
    "        mask = masks[ix].bool()\n",
    "\n",
    "        # Filter padded classes/boxes using the binary mask...\n",
    "        t_cl = t_cl[mask]\n",
    "        t_bbox = t_bbox[mask] * IMAGE_SIZE\n",
    "\n",
    "        # Convert to x1y1x2y2 for visualization and denormalize boxes..\n",
    "        t_bbox = ops.box_convert(\n",
    "            t_bbox, in_fmt='cxcywh', out_fmt='xyxy')\n",
    "        \n",
    "        im = input_[ix]\n",
    "\n",
    "        ax = fig.add_subplot(2, 2, ix+1)\n",
    "        visualizer._visualize_image(im, t_bbox, t_cl, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the DETR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do instantiate the model with the COCO dataset parameters in order to load pre-trained weights\n",
    "# to fine-tune on a new dataset with...\n",
    "detr_model = DETR(\n",
    "    d_model=256, n_classes=92, n_tokens=225, \n",
    "    n_layers=6, n_heads=8, n_queries=MAX_OBJECTS\n",
    ")\n",
    "\n",
    "# Inspect shapes of outputs from the last layer\n",
    "x = torch.randn((1, 3, 480, 480))\n",
    "outs = detr_model(x)\n",
    "pred_cl, pred_boxes = outs['layer_5'].values()\n",
    "\n",
    "print()\n",
    "print(\"*****************************************\")\n",
    "print(f\"Predicted Classes shape: {pred_cl.shape}\")\n",
    "print(f\"Predicted Boxes shape: {pred_boxes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained weights on COCO as a starting point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"<YOUR_COCO_WEIGHTS.pt>\"\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "# Load the weights into the model\n",
    "print(detr_model.load_state_dict(checkpoint['state']))\n",
    "\n",
    "# Adapt the class prediction head to our new dataset\n",
    "detr_model.linear_class = nn.Linear(detr_model.linear_class.in_features, len(CLASSES))\n",
    "\n",
    "# Verify output shapes with the new configurations\n",
    "x = torch.randn((1, 3, 480, 480))\n",
    "outs = detr_model(x)\n",
    "pred_cl, pred_boxes = outs['layer_5'].values()\n",
    "\n",
    "print()\n",
    "print(\"*****************************************\")\n",
    "print(f\"Predicted Classes shape: {pred_cl.shape}\")\n",
    "print(f\"Predicted Boxes shape: {pred_boxes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Enable GPU if available\n",
    "if CUDA_ENABLED:\n",
    "    print(f\"Model moved to GPU for training...\")\n",
    "    detr_model.cuda()\n",
    "else:\n",
    "    print(\"No GPU found, training will start on CPU...\")\n",
    "\n",
    "# DETR in the offical paper is trained with different learning rates for backbone and Transformer/prediction heads.\n",
    "# In this case we will freeze the backbone and train only the Transformer/prediction heads as it's already pre-trained...\n",
    "backbone_params = [\n",
    "    p for n, p in detr_model.named_parameters() if 'backbone.' in n]\n",
    "\n",
    "# Freeze backbone\n",
    "if FREEZE_BACKBONE:\n",
    "    for p in detr_model.backbone.parameters():\n",
    "        p.requires_grad = False\n",
    "print(f\"CNN backbone is frozen for training: {FREEZE_BACKBONE}\")\n",
    "\n",
    "transformer_params = [\n",
    "    p for n, p in detr_model.named_parameters() if 'backbone.' not in n]\n",
    "\n",
    "optimizer = AdamW([\n",
    "    {'params': transformer_params, 'lr': 1e-5},\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "\n",
    "# Log the number of parameters\n",
    "nparams = sum([p.nelement() for p in detr_model.parameters()]) / 1e6\n",
    "print(f'DETR trainable parameters: {nparams:.1f}M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure saving directory exists for the model checkpoints...\n",
    "![ ! -d ckpts ] && mkdir ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to training mode\n",
    "torch.set_grad_enabled(True)\n",
    "detr_model.train()\n",
    "\n",
    "NUM_BATCHES = len(train_loader)\n",
    "\n",
    "losses = torch.tensor([], device=device)\n",
    "class_losses = torch.tensor([], device=device)\n",
    "box_losses = torch.tensor([], device=device)\n",
    "giou_losses = torch.tensor([], device=device)\n",
    "\n",
    "hist = []\n",
    "\n",
    "# More detailed logs for all losses(tuple: (class, bbox, giou))\n",
    "hist_detail = []\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (input_, (tgt_cl, tgt_bbox, tgt_mask)) in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        input_ = input_.to(device)\n",
    "        tgt_cl = tgt_cl.to(device)\n",
    "        tgt_bbox = tgt_bbox.to(device)\n",
    "        tgt_mask = tgt_mask.bool().to(device)\n",
    "\n",
    "        # Run inference\n",
    "        outs = detr_model(input_)\n",
    "\n",
    "        # Accumulate losses\n",
    "        loss = torch.tensor(0.0, device=device)\n",
    "        loss_class_batch = torch.tensor(0.0, device=device)\n",
    "        loss_bbox_batch = torch.tensor(0.0, device=device)\n",
    "        loss_giou_batch = torch.tensor(0.0, device=device)\n",
    "\n",
    "        for name, out in outs.items(): \n",
    "            out['bbox'] = out['bbox'].sigmoid().to(device)\n",
    "            out['cl'] = out['cl'].to(device)\n",
    "            \n",
    "            for o_bbox, t_bbox, o_cl, t_cl, t_mask in zip(\n",
    "                out['bbox'], tgt_bbox, out['cl'], tgt_cl, tgt_mask):\n",
    "        \n",
    "                loss_class, loss_bbox, loss_giou = compute_batch_loss(\n",
    "                    o_bbox, \n",
    "                    t_bbox, \n",
    "                    o_cl, \n",
    "                    t_cl, \n",
    "                    t_mask,\n",
    "                    n_queries=MAX_OBJECTS,\n",
    "                    empty_class_id=EMPTY_CLASS_ID,\n",
    "                    device=device\n",
    "                )\n",
    "                \n",
    "                sample_loss = 1 * loss_class + 5 * loss_bbox + 2 * loss_giou\n",
    "                \n",
    "                loss += sample_loss / BATCH_SIZE / len(outs)\n",
    "\n",
    "                # Track individual losses per batch\n",
    "                loss_class_batch += loss_class / BATCH_SIZE / len(outs)\n",
    "                loss_bbox_batch += loss_bbox / BATCH_SIZE / len(outs)\n",
    "                loss_giou_batch += loss_giou / BATCH_SIZE / len(outs)\n",
    "            \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradient norms\n",
    "        nn.utils.clip_grad_norm_(detr_model.parameters(), .1)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Gather batch-level losses\n",
    "        losses = torch.cat((losses, loss.unsqueeze(0)))\n",
    "        class_losses = torch.cat((class_losses, loss_class_batch.unsqueeze(0)))\n",
    "        box_losses = torch.cat((box_losses, loss_bbox_batch.unsqueeze(0)))\n",
    "        giou_losses = torch.cat((giou_losses, loss_giou_batch.unsqueeze(0)))\n",
    "\n",
    "    # Logging every 10 epochs\n",
    "    if (epoch + 1) % LOG_FREQUENCY == 0:\n",
    "        # Get the epoch losses (averaged from batch losses)\n",
    "        loss_avg = losses[-NUM_BATCHES:].mean().item()\n",
    "        epoch_loss_class = class_losses[-NUM_BATCHES:].mean().item()\n",
    "        epoch_loss_bbox = box_losses[-NUM_BATCHES:].mean().item()\n",
    "        epoch_loss_giou = giou_losses[-NUM_BATCHES:].mean().item()\n",
    "       \n",
    "        # Log the losses\n",
    "        print(f'Epoch: {epoch+1}/{EPOCHS}, DETR Loss: {loss_avg:.4f}')\n",
    "        print(f'→ Class Loss: {epoch_loss_class:.4f}, BBox Loss: {epoch_loss_bbox:.4f}, GIoU Loss: {epoch_loss_giou:.4f}')\n",
    "        \n",
    "        # Save history per epoch...\n",
    "        hist.append(loss_avg)\n",
    "        hist_detail.append((epoch_loss_class, epoch_loss_bbox, epoch_loss_giou))\n",
    "\n",
    "    # Save every 20 epochs\n",
    "    if (epoch + 1) % SAVE_FREQUENCY == 0:\n",
    "        torch.save(detr_model.state_dict(), f'ckpts/model_epoch{epoch+1}.pt')\n",
    "        np.save(f'ckpts/hist_epoch{epoch+1}.npy', hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualizers import visualize_losses\n",
    "\n",
    "# Plot and save the loss plots\n",
    "visualize_losses(hist, hist_detail, save_dir='./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fine-tuned model and test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualizers import DETRBoxVisualizer\n",
    "\n",
    "WEIGHS_PATH = \"../weights/model_epoch20.pt\"\n",
    "INFERENCE_DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Trained on your custom dataset\n",
    "detr_model = DETR(\n",
    "    d_model=256, n_classes=len(CLASSES), n_tokens=225, \n",
    "    n_layers=6, n_heads=8, n_queries=MAX_OBJECTS\n",
    ").to(INFERENCE_DEVICE)\n",
    "\n",
    "# Load the checkpoint\n",
    "print(detr_model.load_state_dict(torch.load(WEIGHS_PATH, map_location=torch.device(INFERENCE_DEVICE))))\n",
    "\n",
    "# Run inference and check results\n",
    "visualizer = DETRBoxVisualizer(class_labels= CLASSES,\n",
    "                               empty_class_id=0)\n",
    "\n",
    "# This will always run inference on a GPU if one is available...\n",
    "visualizer.visualize_validation_inference(detr_model, coco_ds_val, collate_fn=collate_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

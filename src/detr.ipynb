{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing and training a Detection Transformer (DETR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import ops\n",
    "\n",
    "\n",
    "# Import the custom COCO dataset loader\n",
    "from dataloaders.coco_od_pytorch import TorchCOCOLoader, collate_fn\n",
    "from models.detr import DETR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the experiment configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size for dataloaders and image size for model/pre-processing\n",
    "BATCH_SIZE = 4\n",
    "IMAGE_SIZE = 480\n",
    "MAX_OBJECTS = 100\n",
    "FREEZE_BACKBONE = True\n",
    "EPOCHS = 150\n",
    "LOG_FREQUENCY = 5 # Training-time losses will be logged according to this frequency\n",
    "SAVE_FREQUENCY = 20 # Model weights will be saved according to this frequency\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Training device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a PyTorch Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class labels for your custom dataset\n",
    "CLASSES = [\"N/A\", \"chess_piece\"]\n",
    "EMPTY_CLASS_ID = 0 # ID of the dataset classes to treat as \"empty\" class\n",
    "\n",
    "# NOTE: You can instead load the COCO CLASSES if you wish to train on the COCO dataset\n",
    "#       by importing \"from datasets.info import DATASET_CLASSES\". This\n",
    "#       is a lookup dictionary in the format:\n",
    "#       DATASET_CLASSES = {\n",
    "#           \"coco\" : {\n",
    "#               \"class_names\" : COCO_CLASSES,\n",
    "#               \"empty_class_id\": 91,\n",
    "#               \"links\":{\n",
    "#                    \"images\": \"http://images.cocodataset.org/zips/train2017.zip\",\n",
    "#                    \"annotations\": \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\",\n",
    "#           }\n",
    "#           ....\n",
    "#       }\n",
    "# So then you can set \"CLASSES\" = DATASET_CLASSES[\"coco\"][\"class_names\"] and \"EMPTY_CLASS_ID\" = DATASET_CLASSES[\"coco\"][\"empty_class_id\"]\n",
    "\n",
    "\n",
    "# Load and COCO dataset (adjust the paths accordingly)\n",
    "coco_ds_train = TorchCOCOLoader(\n",
    "    '../data/chess_pieces/train',\n",
    "    '../data/chess_pieces/train/_annotations.coco.json',\n",
    "    max_boxes=MAX_OBJECTS,\n",
    "    empty_class_id=EMPTY_CLASS_ID,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")\n",
    "\n",
    "coco_ds_val = TorchCOCOLoader(\n",
    "    '../data/chess_pieces/valid',\n",
    "    '../data/chess_pieces/valid/_annotations.coco.json',\n",
    "    max_boxes=MAX_OBJECTS,\n",
    "    empty_class_id=EMPTY_CLASS_ID,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    coco_ds_train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    coco_ds_val, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "print(f\"Training dataset size: {len(coco_ds_train)}\")\n",
    "print(f\"Validation dataset size: {len(coco_ds_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils.visualizers import DETRBoxVisualizer\n",
    "\n",
    "# Create a visualizer\n",
    "visualizer = DETRBoxVisualizer(class_labels= CLASSES,\n",
    "                               empty_class_id=0)\n",
    "\n",
    "# Visualize batches\n",
    "dataloader_iter = iter(train_loader)\n",
    "for i in range(1):\n",
    "    input_, (classes, boxes, masks, _) = next(dataloader_iter)\n",
    "    fig = plt.figure(figsize=(10, 10), constrained_layout=True)\n",
    "\n",
    "    for ix in range(4):\n",
    "        t_cl = classes[ix]\n",
    "        t_bbox = boxes[ix]\n",
    "        mask = masks[ix].bool()\n",
    "\n",
    "        # Filter padded classes/boxes using the binary mask...\n",
    "        t_cl = t_cl[mask]\n",
    "        t_bbox = t_bbox[mask] * IMAGE_SIZE\n",
    "\n",
    "        # Convert to x1y1x2y2 for visualization and denormalize boxes..\n",
    "        t_bbox = ops.box_convert(\n",
    "            t_bbox, in_fmt='cxcywh', out_fmt='xyxy')\n",
    "        \n",
    "        im = input_[ix]\n",
    "\n",
    "        ax = fig.add_subplot(2, 2, ix+1)\n",
    "        visualizer._visualize_image(im, t_bbox, t_cl, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the DETR model\n",
    "\n",
    "**Note**: If you decide to start from pre-trained weights the `n_classes` argument should\n",
    "match the number of classes the pre-trained model was trained on (e.g. if trained on \"COCO\" then it should be 92 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do instantiate the model with the COCO dataset parameters in order to load pre-trained weights\n",
    "# to fine-tune on a new dataset with...\n",
    "detr_model = DETR(\n",
    "    d_model=256, n_classes=92, n_tokens=225, \n",
    "    n_layers=6, n_heads=8, n_queries=MAX_OBJECTS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained weights as a starting point to explore Transfer Learning (optional)\n",
    "\n",
    "Using pre-trained weights can significantly speed up training as the model doesn't start from 0.\n",
    "\n",
    "Training DETR from scratch might take significant time even with enough GPU horsepower, while with\n",
    "fine-tuning you can get somewhat decent results with 100-150 epochs depending on your dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"<YOUR_DETR_WEIGHTS.pt>\"\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "# Load the weights into the model\n",
    "print(detr_model.load_state_dict(checkpoint['state']))\n",
    "\n",
    "# Adapt the class prediction head to our new dataset\n",
    "detr_model.linear_class = nn.Linear(detr_model.linear_class.in_features, len(CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.trainer import DETRTrainer\n",
    "\n",
    "# Create a trainer for DETR\n",
    "trainer = DETRTrainer(model = detr_model,\n",
    "                      train_loader= train_loader,\n",
    "                      val_loader=val_loader,\n",
    "                      device=device,\n",
    "                      epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      log_freq=5,\n",
    "                      save_freq=SAVE_FREQUENCY,\n",
    "                      freeze_backbone= FREEZE_BACKBONE,\n",
    "                      num_queries=MAX_OBJECTS,\n",
    "                      empty_class_id=EMPTY_CLASS_ID)\n",
    "\n",
    "# Start the training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training metrics and save the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.visualize_losses(save_dir = \"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load fine-tuned model and test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualizers import DETRBoxVisualizer\n",
    "\n",
    "WEIGHS_PATH = \"../weights/chess_100.pt\"\n",
    "INFERENCE_DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Trained on your custom dataset\n",
    "detr_model = DETR(\n",
    "    d_model=256, n_classes=len(CLASSES), n_tokens=225, \n",
    "    n_layers=6, n_heads=8, n_queries=MAX_OBJECTS\n",
    ").to(INFERENCE_DEVICE)\n",
    "\n",
    "# Load the checkpoint\n",
    "print(detr_model.load_state_dict(torch.load(WEIGHS_PATH, map_location=torch.device(INFERENCE_DEVICE))))\n",
    "\n",
    "# Run inference and check results\n",
    "visualizer = DETRBoxVisualizer(class_labels= CLASSES,\n",
    "                               empty_class_id=EMPTY_CLASS_ID)\n",
    "\n",
    "# This will always run inference on a GPU if one is available...\n",
    "visualizer.visualize_validation_inference(detr_model, coco_ds_val, collate_fn=collate_fn, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Or run inference on a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_video_inference(\n",
    "    model=detr_model,\n",
    "    video_path=\"<YOUR_VIDEO_PATH>\",\n",
    "    save_dir= \"<YOUR_SAVE_DIR>\",\n",
    "    image_size=480,\n",
    "    batch_size=3,\n",
    "    nms_threshold=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the trained model using the COCO API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.evaluator import DETREvaluator\n",
    "\n",
    "evaluator = DETREvaluator(detr_model, coco_ds_val, device, EMPTY_CLASS_ID, collate_fn, batch_size=4)\n",
    "stats = evaluator.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
